# -*- coding: utf-8 -*-
"""sistema-moderacao-ia

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rLNXzh2v1Gz8tG6oUhbn3sCP9KeTCnR9
"""

from google.colab import auth
auth.authenticate_user()

import os
import uuid
from google.colab import userdata
from google import genai
from langgraph.graph import StateGraph, END
from langgraph.checkpoint.memory import MemorySaver
from typing import TypedDict, Optional
from IPython.display import Image, display

try:
    # Tenta pegar dos Segredos do Colab
    if "GOOGLE_API_KEY" not in os.environ:
        os.environ["GOOGLE_API_KEY"] = userdata.get('GOOGLE_API_KEY')
        print("‚úÖ API Key configurada.")
except Exception as e:
    print("‚ö†Ô∏è Erro: Verifique se voc√™ criou o segredo 'GOOGLE_API_KEY' no Colab.")

# Criando o Cliente Gemini 2.5
client = genai.Client(api_key=os.environ["GOOGLE_API_KEY"])
MODELO = "gemini-2.5-flash"

class EstadoHibrido(TypedDict):
    texto: str
    # Parte 1: Modera√ß√£o (Python)
    status_moderacao: str
    motivo_bloqueio: Optional[str]
    # Parte 2: Intelig√™ncia (IA)
    analise_ia: Optional[str]
    revisao_ia: Optional[str]
    resultado_final: Optional[str]

def node_moderador(state: EstadoHibrido):
    print(f"üõ°Ô∏è (Moderador): Verificando: '{state['texto']}'")
    texto_lower = state['texto'].lower()

    # Lista de palavras proibidas
    palavras_proibidas = ["idiota", "burro", "lixo", "golpe", "roubar"]

    if any(p in texto_lower for p in palavras_proibidas):
        return {
            "status_moderacao": "Bloqueado",
            "motivo_bloqueio": "Linguagem ofensiva ou suspeita detectada."
        }

    return {"status_moderacao": "Aprovado"}

def node_analista(state: EstadoHibrido):
    print(f"ü§ñ (Gemini 2.5): Analisando risco financeiro...")
    prompt = f"Analise este pedido e recomende uma a√ß√£o t√©cnica banc√°ria: {state['texto']}"

    try:
        response = client.models.generate_content(model=MODELO, contents=prompt)
        return {"analise_ia": response.text}
    except Exception as e:
        return {"analise_ia": f"Erro na IA: {str(e)}"}

def node_revisor(state: EstadoHibrido):
    print("üßê (Revisor): Validando seguran√ßa...")
    prompt = f"O analista disse: '{state['analise_ia']}'. Isso √© seguro para o banco? Resuma em uma frase."

    response = client.models.generate_content(model=MODELO, contents=prompt)
    return {"revisao_ia": response.text}

def node_executor(state: EstadoHibrido):
    print("üöÄ (Sistema): Executando transfer√™ncia...")
    return {"resultado_final": "‚úÖ Opera√ß√£o Conclu√≠da com Sucesso!"}

def roteador_moderacao(state: EstadoHibrido):
    # Decide o caminho baseado no status do Moderador
    if state["status_moderacao"] == "Bloqueado":
        return "fim_bloqueado"
    return "seguir_para_ia"

workflow = StateGraph(EstadoHibrido)

# Adicionando os n√≥s
workflow.add_node("moderador", node_moderador)
workflow.add_node("analista", node_analista)
workflow.add_node("revisor", node_revisor)
workflow.add_node("executor", node_executor)

# Ponto de partida
workflow.set_entry_point("moderador")

# Arestas Condicionais (O desvio inteligente)
workflow.add_conditional_edges(
    "moderador",
    roteador_moderacao,
    {
        "fim_bloqueado": END,
        "seguir_para_ia": "analista"
    }
)

# Fluxo normal
workflow.add_edge("analista", "revisor")
workflow.add_edge("revisor", "executor")
workflow.add_edge("executor", END)

# Compila√ß√£o com Mem√≥ria (Checkpointer)
checkpointer = MemorySaver()
graph = workflow.compile(
    checkpointer=checkpointer,
    interrupt_before=["executor"] # OBRIGAT√ìRIO para aprova√ß√£o humana
)

# Opcional: Mostrar o desenho do grafo
try:
    display(Image(graph.get_graph().draw_mermaid_png()))
except:
    pass

# --- CONFIGURA√á√ÉO DO TESTE ---
texto_input = "Gostaria de transferir 50 mil reais para fornecedor novo"
# texto_input = "Seu sistema √© um lixo" # Descomente para testar o bloqueio

# Gera ID novo para n√£o misturar com testes anteriores
thread_id = str(uuid.uuid4())
config = {"configurable": {"thread_id": thread_id}}

print(f"--- üß™ INICIANDO TESTE (ID: {thread_id}) ---")

# 1. Roda at√© onde der (Pausa ou Fim)
for event in graph.stream({"texto": texto_input}, config):
    pass

# 2. Verifica o estado final
estado_atual = graph.get_state(config).values

# CEN√ÅRIO A: Bloqueado pelo Moderador (Python)
if estado_atual.get("status_moderacao") == "Bloqueado":
    print(f"\n‚ùå BLOQUEADO IMEDIATAMENTE: {estado_atual.get('motivo_bloqueio')}")

# CEN√ÅRIO B: Chegou na Pausa (IA aprovou an√°lise)
elif estado_atual.get("revisao_ia"):
    print(f"\nüõë PAUSA PARA APROVA√á√ÉO HUMANA")
    print(f"Revisor IA disse: {estado_atual['revisao_ia']}")

    decisao = input("\n‚û°Ô∏è Voc√™ AUTORIZA a a√ß√£o final? (s/n): ").strip().lower()

    if decisao == "s":
        print("\n--- Retomando ---")
        for event in graph.stream(None, config):
            if "resultado_final" in event.get("executor", {}):
                print(event["executor"]["resultado_final"])
    else:
        print("\n‚ùå Cancelado pelo humano.")